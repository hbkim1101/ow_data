import requests
import pandas as pd
import time
import html
import json
import os
from bs4 import BeautifulSoup
from itertools import product
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# ===== ì„¤ì •ê°’ =====
MAX_WORKERS = 5  # 5~8 ê¶Œì¥
TIMEOUT_SEC = 30 

def scrape_single_url(args):
    region, gamemode, map_name, tier, date_str = args
    records = []
    
    # URL ìƒì„±
    base_url = "https://overwatch.blizzard.com/ko-kr/rates/"
    params = f"?input=pc&map={map_name}&region={region}&role=All&rq={gamemode}&tier={tier}"
    target_url = base_url + params

    max_retries = 3
    for attempt in range(max_retries):
        try:
            # allow_redirects=Trueë¡œ ë‘¡ë‹ˆë‹¤ (URL í™•ì¸ë³´ë‹¤ëŠ” ë‚´ìš© í™•ì¸ì´ ì¤‘ìš”í•˜ë¯€ë¡œ)
            res = requests.get(target_url, timeout=TIMEOUT_SEC)
            res.raise_for_status()

            # HTML íŒŒì‹±
            soup = BeautifulSoup(res.text, "html.parser")

            # ================================================================
            # ğŸ›¡ï¸ [ì§„ì§œ í•µì‹¬] HTML ë‚´ë¶€ì˜ <option> íƒœê·¸ ê²€ì¦
            # ì„œë²„ê°€ 200 OKë¥¼ ì£¼ë”ë¼ë„, ì‹¤ì œë¡œ ì„ íƒëœ ì˜µì…˜ì´ ë‹¤ë¥¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
            # ================================================================
            
            # (1) ë§µ ê²€ì¦
            if map_name != "all-maps":
                # ë‚´ê°€ ìš”ì²­í•œ ë§µ ì´ë¦„(value)ì„ ê°€ì§„ option íƒœê·¸ë¥¼ ì°¾ê³ , 
                # ê·¸ íƒœê·¸ì— 'selected' ì†ì„±ì´ ìˆëŠ”ì§€ í™•ì¸
                # ì˜ˆ: <option value="hanaoka" selected> ê°€ ìˆì–´ì•¼ í†µê³¼
                selected_map_option = soup.find("option", {"value": map_name, "selected": True})
                
                if not selected_map_option:
                    # print(f"â© [SKIP] Map Mismatch: ìš”ì²­({map_name}) != ê²°ê³¼(HTMLë‚´ ì„ íƒì•ˆë¨)")
                    return []

            # (2) í‹°ì–´ ê²€ì¦
            if tier != "All":
                # í‹°ì–´ ì—­ì‹œ HTML ë‚´ì—ì„œ ì„ íƒë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                selected_tier_option = soup.find("option", {"value": tier, "selected": True})
                
                if not selected_tier_option:
                    # print(f"â© [SKIP] Tier Mismatch: ìš”ì²­({tier}) != ê²°ê³¼(HTMLë‚´ ì„ íƒì•ˆë¨)")
                    return []
            
            # ================================================================

            # ë°ì´í„° ì¶”ì¶œ
            tag = soup.find("blz-data-table")
            if not tag:
                return []

            raw_json = html.unescape(tag["allrows"])
            data = json.loads(raw_json)

            if not data: # ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¢…ë£Œ
                return []

            for hero in data:
                cells = hero.get("cells", {})
                hero_meta = hero.get("hero", {})
                records.append({
                    "date": date_str,
                    "game_mode": "competitive" if gamemode == 1 else "quickplay",
                    "region": region,
                    "map": map_name,
                    "tier": tier,
                    "hero_name": cells.get("name", ""),
                    "role": hero_meta.get("role", ""),
                    "pick_rate(%)": cells.get("pickrate", ""),
                    "win_rate(%)": cells.get("winrate", "")
                })
            
            time.sleep(0.1) 
            return records

        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                # print(f"âŒ [FAIL] {map_name}/{tier}: {e}")
                return [] 

    return []

def main():
    # ===== 0. ê¸°ë³¸ ì„¤ì • =====
    date_str = datetime.now().strftime("%Y-%m-%d")
    season_dir = "Season20"
    season_num = "".join(ch for ch in season_dir if ch.isdigit())
    season_code = f"S{season_num}"
    date_short = datetime.strptime(date_str, "%Y-%m-%d").strftime("%y%m%d")

    save_root = os.path.join(season_dir, date_str)
    os.makedirs(save_root, exist_ok=True)

    print(f"=== Saving data under: {save_root} ===")
    print(f"=== Workers: {MAX_WORKERS} threads ===")

    # ===== 1. ìˆ˜ì§‘ ëŒ€ìƒ ì„¤ì • =====
    gamemodes = [0, 1]
    regions = ["Asia"]
    maps = [
        "all-maps", "throne-of-anubis", "hanaoka", "antarctic-peninsula", "nepal", "lijiang-tower", 
        "busan", "samoa", "oasis", "ilios", "route-66", "watchpoint-gibraltar", "dorado", 
        "rialto", "shambali-monastery", "circuit-royal", "junkertown", "havana", "new-junk-city", 
        "suravasa", "aatlis", "numbani", "midtown", "blizzard-world", "eichenwalde", 
        "kings-row", "paraiso", "hollywood", "new-queen-street", "runasapi", "esperanca", "colosseo"
    ]
    tiers = ["All", "Bronze", "Silver", "Gold", "Platinum", "Diamond", "Master", "Grandmaster"]

    total_rows = 0

    # ===== 2. ì§€ì—­ë³„ ìˆ˜ì§‘ =====
    for region in regions:
        print(f"\n===== ğŸŒ {region} ìˆ˜ì§‘ ì‹œì‘ (Parallel) =====")
        
        tasks = []
        for gamemode, map_name, tier in product(gamemodes, maps, tiers):
            if gamemode == 0 and tier != "All": continue
            elif gamemode == 1 and map_name in ["throne-of-anubis", "hanaoka"]: continue
            
            tasks.append((region, gamemode, map_name, tier, date_str))

        region_records = []
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_url = {executor.submit(scrape_single_url, t): t for t in tasks}
            
            for i, future in enumerate(as_completed(future_to_url)):
                try:
                    data = future.result()
                    if data:
                        region_records.extend(data)
                except Exception as exc:
                    print(f"Error: {exc}")
                
                if (i + 1) % 50 == 0:
                    print(f"   ... {i + 1}/{len(tasks)} ì™„ë£Œ")

        # ===== 3. ì €ì¥ =====
        if region_records:
            df_region = pd.DataFrame(region_records)
            total_rows += len(df_region)

            filename = f"{season_code}_{region}_{date_short}.csv"
            filepath = os.path.join(save_root, filename)
            df_region.to_csv(filepath, index=False, encoding="utf-8-sig")
            print(f"ğŸ’¾ {region} ì €ì¥ ì™„ë£Œ: {len(df_region)} rows")
        else:
            print(f"âš ï¸ {region} ë°ì´í„° ì—†ìŒ")

    print(f"\nğŸ‰ ì „ì²´ ì™„ë£Œ! ì´ ë°ì´í„° í–‰ ìˆ˜: {total_rows}")

    if "GITHUB_ENV" in os.environ:
        with open(os.environ["GITHUB_ENV"], "a") as f:
            f.write(f"TOTAL_ROWS={total_rows}\n")

if __name__ == "__main__":
    main()
